---
content_type: page
is_media_gallery: true
title: Unit 4. Visual Intelligence
uid: 289e2ca7-7ee3-0e59-cb99-42b74cd2ddf9
---

Unit Overview
-------------

| ![A 3x3 grid of photos: top row "memorable" includes a giant inflatable gorilla; middle row "average" includes a grocery store produce section; bottom "forgettable" includes generic landscapes.](BASEURL_PLACEHOLDER/resources/unit4) |  {{< br >}}{{< br >}} What makes an image memorable? Using insights from perceptual experiments, fMRI studies, and computational modeling, Aude Oliva has identified some key factors that determine visual memorability. {{< br >}}{{< br >}} (Image based on Isola, Phillip, Jianxiong Xiao, Devi Parikh, Antonio Torralba, and Aude Oliva. "What Makes a Photograph Memorable?" _IEEE Trans. Pattern Anal. Mach. Intell_. 36, no. 7 (July 2014): 1469–1482. From [author's final manuscript](https://dspace.mit.edu/handle/1721.1/90984), license [CC BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/).) {{< br >}}{{< br >}}  

How do we obtain a rich understanding of the world from visual input? What visual cues enable us to recognize objects from their structure or texture, or to remember objects and scenes that we have encountered before? What is the future for intelligent systems that can drive a car or assist the visually impaired? This unit explores these questions from the perspectives of perception and cognition, brain imaging, and the engineering of intelligent systems.

From very rudimentary visual abilities present at birth, infants learn to recognize complex objects such as hands and how to detect the direction of gaze of a caregiver. Shimon Ullman's first lecture shows how such capabilities can be learned from a stream of natural videos and without supervision.

Shimon Ullman's second lecture explores the minimal configurations of image content needed to recognize an object category, revealing a human capability that far surpasses that of current recognition systems and yielding insights into the brain mechanisms underlying visual recognition.

Understanding what makes an image memorable can shed light on the representations of visual knowledge in the brain and neural basis of memory loss, and is important for applications such as data visualization and image retrieval. From Aude Oliva, you will learn about the visual cues that govern memorability, revealed from behavioral experiments, computational models, and brain imaging studies.

Guest speaker Eero Simoncelli presents a physiologically inspired model of the analysis of visual textures by the ventral pathway of the brain. The synthesis of texture metamers, stimuli that are physically different but appear the same to a human observer, provide a powerful tool for probing the underlying brain mechanisms.

We are rapidly approaching a time of fully autonomous vehicles and intelligent systems to assist the blind. Guest speaker Amnon Shashua shows how advanced computer vision technology created by Mobileye will change transportation, and how wearable devices created by OrCam can profoundly impact the lives of the visually impaired.

Unit Activities
---------------

### Useful Background

*   Introductions to machine learning, neuroscience, cognitive science

### Videos and Slides{{< video-gallery-item href="/resources/lecture-4" section="Unit 4. Visual Intelligence" title="Lecture 4.1: Shimon Ullman - Development of Visual Concepts" description="Description: Visual understanding evolves from simple innate biases to complex visual concepts. How computer models can learn to recognize hands and follow gaze by leveraging simple motion and pattern detection processes present in early infancy. Instructor: Shimon Ullman" thumbnail="https://img.youtube.com/vi/ggcbVV3Tquo/default.jpg" >}} {{< video-gallery-item href="/resources/lecture-4-1" section="Unit 4. Visual Intelligence" title="Lecture 4.2: Shimon Ullman - Atoms of Recognition" description="Description: Human ability to recognize object categories from minimal content in natural image fragments, inadequacy of current computer vision models to capture this ability, discerning the minimal features needed to make inferences for object recognition. Instructor: Shimon Ullman" thumbnail="https://img.youtube.com/vi/Xj4nKgJW5yE/default.jpg" >}} {{< video-gallery-item href="/resources/lecture-4-2" section="Unit 4. Visual Intelligence" title="Lecture 4.3: Aude Oliva - Predicting Visual Memory" description="Description: What makes an image memorable? Discussing visual memory experiments, consistency of memorability across observers, memorability of images, neural framework for memorability, and biologically inspired deep neural network model of object recognition. Instructor: Aude Oliva" thumbnail="https://img.youtube.com/vi/43kansULeBE/default.jpg" >}} {{< video-gallery-item href="/resources/seminar-4" section="Unit 4. Visual Intelligence" title="Seminar 4.1: Eero Simoncelli - Probing Sensory Representations" description="Description: Cognitive processing of sensory input, probing sensory representations with metameric stimuli, perceptual color matching, texture discrimination, Julesz texture model, modeling physiological mechanisms of texture processing in the ventral visual pathway. Instructor: Eero Simoncelli" thumbnail="https://img.youtube.com/vi/eKKXJyabCAQ/default.jpg" >}} {{< video-gallery-item href="/resources/seminar-4-1" section="Unit 4. Visual Intelligence" title="Seminar 4.2: Amnon Shashua - Applications of Vision" description="Description: Using computer vision to develop transportation technology. Covers the technology and function of autonomous vehicles, visual recognition and processing, collision avoidance and other obstacles to achieving fully autonomous, self driving vehicles. Instructor: Amnon Shashua" thumbnail="https://img.youtube.com/vi/TjrRSOHQACw/default.jpg" >}}
Further Study
-------------

Additional information about the speakers' research and publications can be found at their websites:

*   [Aude Oliva, Computational Perception and Cognition Lab, MIT](http://cvcl.mit.edu/Aude.htm)
*   [Amnon Shashua, Hebrew University of Jerusalem](http://www.cs.huji.ac.il/~shashua/); also see industry websites [OrCam](https://www.orcam.com), [Mobileye](https://www.mobileye.com/)
*   [Eero Simoncelli, Laboratory for Computational Vision, NYU](http://www.cns.nyu.edu/~lcv/)
*   [Shimon Ullman, MIT and The Weizmann Institute](http://www.wisdom.weizmann.ac.il/~shimon/)

Bylinskii, Z., P. Isola, et al. ![This resource may not render correctly in a screen reader.](/images/inacessible.gif)["Intrinsic and Extrinsic Effects on Image Variability." (PDF - 4.8MB)](http://web.mit.edu/zoya/www/docs/figrimProof.pdf) _Vision Research_ 116 Part B (2015): 165–78.

Cichy, R. M., A. Khosla, et al. "[Dynamics of Scene Representations in the Human Brain Revealed by Magnetoencephalography and Deep Neural Networks](http://dx.doi.org/10.1016/j.neuroimage.2016.03.063)." _NeuroImage_ (2016). (in press)

Freeman, J., and E. P. Simoncelli. ![This resource may not render correctly in a screen reader.](/images/inacessible.gif)["Metamers of the Ventral Stream." (PDF - 2.0MB)](http://www.cns.nyu.edu/pub/eero/freeman10-reprint.pdf) _Nature Neuroscience_ 14, no. 9 (2011): 1195–1201.

Freeman, J., C. M. Ziemba, et al. ![This resource may not render correctly in a screen reader.](/images/inacessible.gif)["A Functional and Perceptual Signature of the Second Visual Area in Primates." (PDF - 1.5MB)](http://www.cns.nyu.edu/pub/lcv/freeman13-reprint.pdf) _Nature Neuroscience_ 16, no. 7 (2013): 974–81.

Portilla, J., and E. P. Simoncelli. ![This resource may not render correctly in a screen reader.](/images/inacessible.gif)["A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients." (PDF - 2.0MB)](http://www.cns.nyu.edu/pub/eero/portilla99-reprint.pdf) _International Journal of Computer Vision_ 40, no. 1 (2000): 49–71.

Ullman, S., L. Assif, et al. ![This resource may not render correctly in a screen reader.](/images/inacessible.gif)["Atoms of Recognition in Human and Computer Vision." (PDF)](http://www.pnas.org/content/113/10/2744.full.pdf) _Proceedings of the National Academy of Sciences_ 113, no. 10 (2016): 2744–49.

Ullman, S., D. Harari, et al. ![This resource may not render correctly in a screen reader.](/images/inacessible.gif)["From Simple Innate Biases to Complex Visual Concepts." (PDF - 2.5MB)](http://cs.wellesley.edu/~vision/papers/Ullman_PNAS_2012_with_SI.pdf) _Proceedings of the National Academy of Sciences_ 109, no. 44 (2012): 18215–20.

Zhou, B., A. Khosla, et al. ![This resource may not render correctly in a screen reader.](/images/inacessible.gif)["Object Detectors Emerge in Deep Scene CNNs." (PDF - 7.0MB)](http://arxiv.org/pdf/1412.6856.pdf) _International Conference on Learning Representations_ (2015).